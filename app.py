import streamlit as st
from transformers import pipeline
import torch

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="AI vs Human æ–‡æœ¬åµæ¸¬å™¨",
    page_icon="ğŸ¤–",
    layout="centered"
)

# å¿«å–æ¨¡å‹ï¼Œé¿å…æ¯æ¬¡é‡æ–°è¼‰å…¥ (Streamlit Cache)
@st.cache_resource
def load_model():
    # ä½¿ç”¨ Hugging Face ä¸Šè¼ƒè¼•é‡ä¸”ç†±é–€çš„ ChatGPT åµæ¸¬æ¨¡å‹
    model_name = "Hello-SimpleAI/chatgpt-detector-roberta"
    
    # å»ºç«‹åˆ†é¡ pipeline
    # return_all_scores=True æœƒåŒæ™‚å›å‚³ Human å’Œ AI çš„æ©Ÿç‡
    classifier = pipeline("text-classification", model=model_name, top_k=None)
    return classifier

# å´é‚Šæ¬„è³‡è¨Š
st.sidebar.title("é—œæ–¼å·¥å…·")
st.sidebar.info(
    "æ­¤å·¥å…·ä½¿ç”¨ Transformer æ¨¡å‹ (RoBERTa) "
    "ä¾†åˆ†ææ–‡æœ¬çš„èªæ³•èˆ‡çµ±è¨ˆç‰¹å¾µï¼Œåˆ¤æ–·æ˜¯å¦ç”± AI ç”Ÿæˆã€‚"
)
st.sidebar.warning(
    "âš ï¸ æ³¨æ„ï¼šAI åµæ¸¬å™¨ä¸¦é 100% æº–ç¢ºï¼Œ"
    "çµæœåƒ…ä¾›åƒè€ƒï¼Œè«‹å‹¿ä½œç‚ºå–®ä¸€è©•åˆ¤æ¨™æº–ã€‚"
)

# ä¸»æ¨™é¡Œ
st.title("ğŸ¤– AI / ğŸ§‘ Human æ–‡ç« åµæ¸¬å™¨")
st.markdown("è¼¸å…¥ä¸€æ®µæ–‡æœ¬ï¼ŒAI å°‡åˆ†æå…¶ç”±äººé¡æˆ–äººå·¥æ™ºæ…§æ’°å¯«çš„å¯èƒ½æ€§ã€‚")

# è¼‰å…¥æ¨¡å‹ (é¡¯ç¤ºè¼‰å…¥ä¸­çš„ spinner)
with st.spinner("æ­£åœ¨è¼‰å…¥ AI åµæ¸¬æ¨¡å‹..."):
    classifier = load_model()

# æ–‡æœ¬è¼¸å…¥å€
user_input = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç« å…§å®¹ (å»ºè­°è‹±æ–‡æ•ˆæœè¼ƒä½³ï¼Œä¸­æ–‡äº¦å¯å˜—è©¦)ï¼š", height=200)

if st.button("é–‹å§‹åˆ†æ"):
    if not user_input.strip():
        st.error("è«‹è¼¸å…¥æ–‡å­—å…§å®¹ï¼")
    else:
        # é€²è¡Œé æ¸¬
        # Truncation=True ç¢ºä¿è¶…é 512 tokens çš„é•·æ–‡ä¸æœƒå ±éŒ¯
        try:
            results = classifier(user_input, truncation=True, max_length=512)
            
            # è§£æçµæœ (çµæœé€šå¸¸æ˜¯ä¸€å€‹ list åŒ…å« dict)
            # Hello-SimpleAI æ¨¡å‹çš„æ¨™ç±¤é€šå¸¸æ˜¯ 'Human' å’Œ 'ChatGPT'
            # æˆ‘å€‘éœ€è¦å°‡å…¶æ¨™æº–åŒ–
            scores = {item['label']: item['score'] for item in results[0]}
            
            # å–å¾—å„åˆ¥åˆ†æ•¸ (è™•ç†æ¨™ç±¤åç¨±å¯èƒ½ä¸åŒçš„æƒ…æ³)
            ai_score = scores.get('ChatGPT', scores.get('Fake', 0.0))
            human_score = scores.get('Human', scores.get('Real', 0.0))
            
            # ç¢ºä¿ç¸½å’Œç‚º 1 (é›–ç„¶ softmax å·²ç¶“åšéï¼Œä½†ä¿éšªèµ·è¦‹)
            total = ai_score + human_score
            ai_prob = (ai_score / total) * 100
            human_prob = (human_score / total) * 100

            # --- é¡¯ç¤ºçµæœ ---
            st.markdown("---")
            st.subheader("ğŸ“Š åˆ†æçµæœ")

            # ä½¿ç”¨ Streamlit çš„ columns é€²è¡Œæ’ç‰ˆ
            col1, col2 = st.columns(2)

            with col1:
                st.metric(label="ğŸ¤– AI å¯èƒ½æ€§", value=f"{ai_prob:.1f}%")
            with col2:
                st.metric(label="ğŸ§‘ äººé¡å¯èƒ½æ€§", value=f"{human_prob:.1f}%")

            # é€²åº¦æ¢è¦–è¦ºåŒ–
            st.write("AI å‚¾å‘ç¨‹åº¦ï¼š")
            st.progress(int(ai_prob))
            
            # åˆ¤æ–·çµè«–
            if ai_prob > 80:
                st.error("ğŸ•µï¸ çµè«–ï¼šé€™ç¯‡æ–‡ç«  **æ¥µé«˜æ©Ÿç‡** æ˜¯ç”± AI ç”Ÿæˆçš„ã€‚")
            elif ai_prob > 50:
                st.warning("ğŸ¤” çµè«–ï¼šé€™ç¯‡æ–‡ç«  **å¯èƒ½** åŒ…å« AI ç”Ÿæˆçš„å…§å®¹ã€‚")
            else:
                st.success("ğŸ“ çµè«–ï¼šé€™ç¯‡æ–‡ç«  **æ¥µé«˜æ©Ÿç‡** æ˜¯ç”±äººé¡æ’°å¯«çš„ã€‚")
            
            # é¡¯ç¤ºåŸå§‹æ•¸æ“š (Debug ç”¨ï¼Œå¯é¸)
            with st.expander("æŸ¥çœ‹åŸå§‹æ¨¡å‹æ•¸æ“š"):
                st.json(results)

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
